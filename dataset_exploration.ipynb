{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from summarytools import dfSummary\n",
    "import json\n",
    "from germansentiment import SentimentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_data = pd.read_csv('dataset/click_data.csv')\n",
    "emotional_events = pd.read_csv('dataset/emotional_events.csv')\n",
    "messages_data = pd.read_csv('dataset/messages_data.csv')\n",
    "# task_types = pd.read_csv('dataset/task_types.csv')\n",
    "user_information = pd.read_csv('dataset/user_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data Types\n",
    "emotional_events['valence'] = emotional_events['valence'].replace('AO07', '7').astype(float)\n",
    "emotional_events['arousal'] = emotional_events['arousal'].replace('AO07', '7').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Data\n",
    "\n",
    "ee = emotional_events[emotional_events['task_type'] == 'information_finding']\n",
    "len(ee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Emotion Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee['arousal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee['valence'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee['valence_high'] = np.where(ee['valence'] > 3, 1, 0)\n",
    "ee['arousal_high'] = np.where(ee['arousal'] > 3, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x: valence\n",
    "y: arousal\n",
    "\n",
    "|2|4|\n",
    "|---|---|\n",
    "|1|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_score(df):\n",
    "    if df['valence_high'] == 1 and df['arousal_high'] == 1:\n",
    "        return 4\n",
    "    elif df['valence_high'] == 1 and df['arousal_high'] == 0:\n",
    "        return 3\n",
    "    elif df['valence_high'] == 0 and df['arousal_high'] == 1:\n",
    "        return 2\n",
    "    elif df['valence_high'] == 0 and df['arousal_high'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "ee['emotion_quartile'] = ee.apply(get_emotion_score, axis=1)\n",
    "ee.emotion_quartile.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellung der neuen Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_data['agent_output'] = messages_data['input'].apply(lambda x: json.loads(x).get('output'))\n",
    "messages_data['user_input'] = messages_data['input'].apply(lambda x: json.loads(x).get('input'))\n",
    "messages_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.drop(columns='id', inplace=True)\n",
    "ee.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No answer given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation ended in a technical error\n",
    "df = pd.merge(ee, messages_data, left_on=['userId', 'task'], right_on=['userId', 'task'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_answer_given'] = df['agent_output'] == \"Leider habe ich keine Antwort auf diese Frage. Versuchen Sie bitte Ihre Frage anders zu formulieren, oder komplexe Fragestellungen in einfachere Fragen zu unterteilen.\"\n",
    "print(df.no_answer_given.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentModel()\n",
    "texts = [\n",
    "    \"Mit keinem guten Ergebniss\",\"Das ist gar nicht mal so gut\",\n",
    "    \"Total awesome!\",\"nicht so schlecht wie erwartet\",\n",
    "    \"Der Test verlief positiv.\",\"Sie fährt ein grünes Auto.\"]\n",
    "       \n",
    "model.predict_sentiment([\"Mit keinem guten Ergebniss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_y'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_messages = pd.json_normalize(messages_data['input'].apply(json.loads).tolist()).values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = model.predict_sentiment(unpacked_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_histplot = user_information.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_for_histplot:\n",
    "    \n",
    "    sns.histplot(user_information[col])\n",
    "    plt.title(col)\n",
    "    plt.savefig(f'{col}_histplot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfSummary(messages_data)\n",
    "# dfSummary(emotional_events)\n",
    "# dfSummary(user_information)\n",
    "# dfSummary(click_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information['data_analysis_experience_bins'] = pd.cut(user_information['experience_analysis_tools'], bins=[0, 3, 5, 7], labels=['3 and lower', '4', '5 and higher'])\n",
    "user_information['data_analysis_experience_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_with_avg_valence = user_information.merge(emotional_events.groupby('userId')['valence'].mean().reset_index(), left_on='id', right_on='userId', how='left')\n",
    "user_info_with_avg_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(user_info_with_avg_valence[user_info_with_avg_valence['data_analysis_experience_bins'] == \"5 and higher\"]['valence'])\n",
    "plt.title('Valence for users with 5 and higher experience')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(user_info_with_avg_valence[user_info_with_avg_valence['data_analysis_experience_bins'] == \"3 and lower\"]['valence'])\n",
    "plt.title('Valence for users with 3 and lower experience')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information['age_bins'] = pd.cut(user_information['age'], bins=[0, 30, 50, 200], labels=['0-30', '30-50', 'older'])\n",
    "user_info_with_avg_valence = user_information.merge(emotional_events.groupby('userId')['valence'].mean().reset_index(), left_on='id', right_on='userId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in user_info_with_avg_valence['age_bins'].unique():\n",
    "    subset = user_info_with_avg_valence[user_info_with_avg_valence['age_bins'] == bins]\n",
    "    sns.histplot(subset['valence'])\n",
    "    plt.title(f'Valence for users in {bins} age group')\n",
    "    plt.savefig(f'valence_{bins}_age.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information['satisfaction_bins'] = pd.cut(user_information['Satisfaction'], bins=[0, 3, 5, 7], labels=['3 and lower', '4', '5 and higher'])\n",
    "user_info_with_avg_valence = user_information.merge(emotional_events.groupby('userId')['valence'].mean().reset_index(), left_on='id', right_on='userId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in user_info_with_avg_valence['satisfaction_bins'].unique():\n",
    "    subset = user_info_with_avg_valence[user_info_with_avg_valence['satisfaction_bins'] == bins]\n",
    "    sns.histplot(subset['valence'])\n",
    "    plt.title(f'Valence for users with {bins} satisfaction')\n",
    "    plt.savefig(f'valence_{bins}_satisfaction.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information['trust_bins'] = pd.cut(user_information['Trust 1'], bins=[0, 3, 5, 7], labels=['3 and lower', '4', '5 and higher'])\n",
    "user_info_with_avg_valence = user_information.merge(emotional_events.groupby('userId')['valence'].mean().reset_index(), left_on='id', right_on='userId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in user_info_with_avg_valence['trust_bins'].unique():\n",
    "    subset = user_info_with_avg_valence[user_info_with_avg_valence['trust_bins'] == bins]\n",
    "    sns.histplot(subset['valence'])\n",
    "    plt.title(f'Valence for users with {bins} trust (1)')\n",
    "    plt.savefig(f'valence_for_users_with_{bins}_trust.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_with_avg_valence = user_information.merge(emotional_events.groupby('userId')['valence'].mean().reset_index(), left_on='id', right_on='userId', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in user_info_with_avg_valence['education'].unique():\n",
    "    subset = user_info_with_avg_valence[user_info_with_avg_valence['education'] == bins]\n",
    "    sns.histplot(subset['valence'])\n",
    "    plt.title(f'Valence for users with {bins} education')\n",
    "    plt.savefig(f'Valence for users with {bins} education.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mögliche Ideen\n",
    "- wie wirkt sich der Assistent auf die Nutzer aus, je nach dem ob sie Vorerfahrung mit Datenanalyse haben oder nicht?\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
